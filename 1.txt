import pymysql
import re
import httpx
import asyncio
import os
import json
import cloudscraper
from unidecode import unidecode
from datetime import datetime
import time
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
import gc
from datetime import datetime, timedelta
import random
import asyncio
from lxml import etree
from lxml.html import fromstring, tostring, etree
from bs4 import BeautifulSoup

# Khai báo thời gian bắt đầu public
Lenlich = datetime.strptime('2025-03-12 01:05:00', '%Y-%m-%d %H:%M:%S')

# Màu chữ
BLACK = "\033[30m"
RED = "\033[31m"
GREEN = "\033[32m"
YELLOW = "\033[33m"
BLUE = "\033[34m"
MAGENTA = "\033[35m"
CYAN = "\033[36m"
WHITE = "\033[37m"

# Màu nền
BG_BLACK = "\033[40m"
BG_RED = "\033[41m"
BG_GREEN = "\033[42m"
BG_YELLOW = "\033[43m"
BG_BLUE = "\033[44m"
BG_MAGENTA = "\033[45m"
BG_CYAN = "\033[46m"
BG_WHITE = "\033[47m"

# In đậm và reset
BOLD = "\033[1m"
RESET = "\033[0m"

def allocate_id_range(batch_size):
    """
    Cấp phát dải ID từ cơ sở dữ liệu cho mỗi cửa sổ.
    """
    try:
        with connection.cursor() as cursor:
            # Kiểm tra và lấy current_id từ bảng id_manager
            cursor.execute("SELECT current_id FROM id_manager WHERE id_name = 'apps' FOR UPDATE")
            result = cursor.fetchone()

            if result is None:
                # Nếu không tìm thấy, tạo bản ghi mới
                print(f"{RED}Không tìm thấy bản ghi 'apps' trong bảng id_manager. Tạo bản ghi mới với current_id = 400.{RESET}")
                cursor.execute("INSERT INTO id_manager (id_name, current_id) VALUES ('apps', 400)")
                connection.commit()
                start_id = 400
            else:
                # Nếu có bản ghi, lấy giá trị current_id hiện tại
                start_id = result['current_id']
                print(f"{GREEN}Lấy dải ID từ {start_id} đến {start_id + batch_size - 1}{RESET}")

            # Cập nhật current_id sau khi lấy
            end_id = start_id + batch_size
            cursor.execute("UPDATE id_manager SET current_id = %s WHERE id_name = 'apps'", (end_id,))
            connection.commit()

            print(f"{GREEN}Đã cập nhật current_id thành {end_id}{RESET}")

            return start_id, end_id  # Trả về dải ID
    except Exception as e:
        print(f"Lỗi khi cấp phát dải ID: {e}")
        connection.rollback()
        raise


class IDAllocator:
    def __init__(self, start_id, end_id):
        self.current_id = start_id
        self.end_id = end_id

    def get_next_id(self):
        if self.current_id > self.end_id:
            raise Exception("No more IDs available in this range")
        next_id = self.current_id
        self.current_id += 1
        return next_id

# Khởi tạo biến connection toàn cục
connection = None

def create_new_connection():
    global connection  # Thêm dòng này
    try:
        connection = pymysql.connect(
            host='103.47.192.7',
            user='haihn_remote',
            password='jN6j9zDd2aqUEkwXrNHB!',
            database='apkhay_v3',
            charset='utf8mb4',
            cursorclass=pymysql.cursors.DictCursor
        )
        print("Kết nối mới đã được tạo thành công.")
    except pymysql.MySQLError as e:
        print(f"Lỗi khi tạo kết nối mới: {e}")
        connection = None  # Đặt lại connection là None nếu không kết nối được

# Gọi hàm tạo kết nối mới trước khi bắt đầu cào
create_new_connection()

# Hàm xóa thuộc tính class và loại bỏ các thẻ div
def clean_html_content(html_content):
    soup = BeautifulSoup(html_content, 'lxml')  # Changed to lxml for better performance

    # Loại bỏ tất cả các thẻ <div>
    for div_tag in soup.find_all('div'):
        div_tag.unwrap()  # Loại bỏ thẻ <div> nhưng giữ lại nội dung bên trong

    # Loại bỏ tất cả các thẻ <body>
    for body_tag in soup.find_all('body'):
        body_tag.unwrap()  # Loại bỏ thẻ <div> nhưng giữ lại nội dung bên trong

        # Loại bỏ tất cả các thẻ <html>
    for html_tag in soup.find_all('html'):
        html_tag.unwrap()  # Loại bỏ thẻ <div> nhưng giữ lại nội dung bên trong    

    # Xóa thuộc tính class khỏi tất cả các thẻ <p>
    for p_tag in soup.find_all('p'):
        if 'class' in p_tag.attrs:
            del p_tag['class']  # Xóa thuộc tính class

    # Trả về chuỗi HTML giữ nguyên thẻ <p>
    return str(soup)

# Hàm lấy URL ảnh từ gallery HTML
def extract_gallery_urls(soup):
    """
    Hàm lấy URL ảnh từ gallery HTML.
    Trả về danh sách các cặp (thumbnail_url, full_image_url).
    """
    gallery_urls = []
    
    # Tìm thẻ div có class 'gallery beauty-scroll mb-14'
    gallery_divs = soup.xpath("//div[contains(@class, 'gallery') and contains(@class, 'beauty-scroll') and contains(@class, 'mb-14')]")
    
    if gallery_divs:
        gallery_div = gallery_divs[0]  # Lấy thẻ div đầu tiên (giả định chỉ có một thẻ gallery)

        # Tìm tất cả các thẻ <a> bên trong thẻ div gallery
        gallery_links = gallery_div.xpath(".//a")
        
        for link in gallery_links:
            # Lấy URL ảnh lớn từ thuộc tính 'data-href' hoặc 'href'
            full_image_url = link.attrib.get('data-href') or link.attrib.get('href')
            
            # Lấy thẻ <img> bên trong thẻ <a> và trích xuất URL ảnh thu nhỏ
            img_tag = link.xpath(".//img")
            thumbnail_url = (
                img_tag[0].attrib.get('data-src') or img_tag[0].attrib.get('src')
                if img_tag
                else None
            )
            
            # Thêm cặp (thumbnail_url, full_image_url) vào danh sách
            if full_image_url and thumbnail_url:
                gallery_urls.append((thumbnail_url, full_image_url))
    
    return gallery_urls

# Hàm kiểm tra xem có phải tiếng Latin mở rộng hay không (bao gồm cả ký tự có dấu và ký tự mở rộng)
def is_latin(text):
    return bool(re.match(r"^[a-zA-Z0-9\s\-\u00C0-\u024F\u1E00-\u1EFF]+$", text))

def generate_slug(name):
    # Thay thế khoảng trắng bằng dấu gạch ngang
    slug = re.sub(r'\s+', '-', name)

    # Loại bỏ các ký tự đặc biệt không mong muốn, giữ lại các ngôn ngữ chính và cụm ký tự gốc
    slug = re.sub(r'[^a-zA-Z0-9\-'
                  r'\u3131-\uD79D'  # Tiếng Hàn
                  r'\u3040-\u30FF'  # Tiếng Nhật
                  r'\u4E00-\u9FFF'  # Tiếng Trung
                  r'\u0E00-\u0E7F'  # Tiếng Thái
                  r'\u0600-\u06FF'  # Tiếng Ả Rập
                  r'\u0900-\u097F'  # Tiếng Hindi
                  r'\u0980-\u09FF'  # Tiếng Bengali
                  r'\u0A00-\u0A7F'  # Tiếng Punjabi
                  r'\u0B00-\u0B7F'  # Tiếng Oriya
                  r'\u0B80-\u0BFF'  # Tiếng Tamil
                  r'\u0C00-\u0C7F'  # Tiếng Telugu
                  r'\u0C80-\u0CFF'  # Tiếng Kannada
                  r'\u0D00-\u0D7F'  # Tiếng Malayalam
                  r'\u0400-\u04FF'  # Chữ Cyrillic
                  r'\u0370-\u03FF'  # Chữ Hy Lạp
                  r'\u0590-\u05FF'  # Tiếng Do Thái
                  r'\u1E00-\u1EFF'  # Chữ Latinh mở rộng
                  r'\u0100-\u017F'  # Chữ Latinh mở rộng thêm
                  r'ぁ-ゔァ-ヴー々〆〤一-龥]', '', slug)

    # Loại bỏ các dấu gạch ngang liên tiếp
    slug = re.sub(r'-+', '-', slug)

    # Loại bỏ gạch ngang ở đầu hoặc cuối slug
    slug = slug.strip('-')

    return slug

# Hàm load categories từ file TXT đã xử lý
def load_categories_from_txt(file_path):
    categories = {}
    with open(file_path, 'r', encoding='utf-8') as file:
        lines = file.readlines()
        for i in range(0, len(lines), 3):  # Mỗi mục có 3 dòng: id, slug, dòng trắng
            category_id = int(lines[i].strip().split(": ")[1])  # Lấy id
            category_slug = lines[i+1].strip().split(": ")[1]  # Lấy slug
            categories[category_slug] = category_id
    return categories

# Đọc danh mục từ file txt
categories = load_categories_from_txt('categories_output.txt')

# Hàm lấy slug từ URL và chuyển đổi dấu gạch
def extract_slug_from_url(url):
    slug = url.split("/")[-1]  # Lấy phần cuối cùng của URL
    return slug.replace("_", "-")  # Chuyển từ "_" thành "-" để so sánh với file txt

# Hàm lấy slug từ URL và chuyển đổi dấu gạch
def extract_slug_from_url(url):
    slug = url.split("/")[-2]  # Lấy phần áp chót của URL (bỏ đi "/category/")
    if "_" in slug:
        slug = slug.replace("_", "-")  # Chuyển từ "_" thành "-" nếu có dấu "_"
    return slug

# Hàm xử lý breadcrumb
def map_category_from_breadcrumbs(breadcrumb_links):
    categories_list = []
    for href in breadcrumb_links:
        #href = link.get('href')  # Lấy thuộc tính href của thẻ a
        if href:
            # Lấy slug từ URL và chuyển về chữ thường
            category_slug = extract_slug_from_url(href).lower()
            print(f"Slug được trích xuất: {category_slug}")  # In ra slug để kiểm tra

            # Xử lý đặc biệt cho 'games' và 'apps'
            if category_slug in ["game", "games"]:
                print("Phát hiện danh mục cha 'games', gán ID 2")
                categories_list.insert(0, 2)  # Gán ID danh mục cha là 2 (games)
                continue  # Tiếp tục vòng lặp để xử lý các danh mục con
            
            if category_slug in ["apps", "app"]:
                print("Phát hiện danh mục cha 'apps', gán ID 1")
                categories_list.insert(0, 1)  # Gán ID danh mục cha là 1 (apps)
                continue  # Tiếp tục vòng lặp để xử lý các danh mục con

            # Kiểm tra xem slug đã trích xuất có trong file txt không
            category_id = categories.get(category_slug, None)
            
            # Thêm log để kiểm tra kỹ xem file txt có chứa slug hay không
            if category_id:
                print(f"Slug khớp trong file txt: {category_slug}, ID: {category_id}")  # In log khi tìm thấy slug
                categories_list.append(category_id)
            else:
                print(f"Không tìm thấy slug trong file txt: {category_slug}")  # In log khi không tìm thấy slug
                print("Kiểm tra lại file txt hoặc slug trong URL.")
                print(f"Các slug có trong file txt: {list(categories.keys())[:10]}...")  # In ra một phần các slug trong file để kiểm tra

    return categories_list

# Hàm lấy id lớn nhất từ bảng apps
def get_max_app_id(connection):
    with connection.cursor() as cursor:
        cursor.execute("SELECT MAX(id) AS max_id FROM apps")
        result = cursor.fetchone()
        return result['max_id'] if result['max_id'] is not None else 0  # Kiểm tra kết quả trả về


# Hàm lưu file vào bảng app_files
def save_app_file_to_database(file_data, app_id, connection):
    with connection.cursor() as cursor:
        # Kiểm tra xem app_id đã tồn tại trong bảng app_files hay chưa
        cursor.execute("SELECT id FROM app_files WHERE app_id = %s", (app_id,))
        existing_file = cursor.fetchone()
        
        if existing_file:
            # Nếu đã tồn tại, cập nhật thông tin
            sql_update_query = """
            UPDATE app_files 
            SET google_play_id = %s, file_size = %s, apkpure_version_code = %s
            WHERE app_id = %s
            """
            cursor.execute(sql_update_query, (
                file_data['google_play_id'], 
                file_data['file_size'], 
                'latest',  # Luôn cập nhật là 'latest'
                app_id
            ))
            print(f"{GREEN}Cập nhật thành công thông tin file cho app_id {app_id}{RESET}")
        else:
            # Nếu chưa tồn tại, thêm mới
            sql_insert_query = """
            INSERT INTO app_files (id, app_id, google_play_id, file_size, apkpure_version_code) 
            VALUES (%s, %s, %s, %s, %s)
            """
            cursor.execute(sql_insert_query, (
                app_id,  # Sử dụng cùng giá trị app_id từ bảng apps cho cả id và app_id
                app_id,  # Cột app_id sẽ có cùng giá trị với id từ bảng apps
                file_data['google_play_id'], 
                file_data['file_size'], 
                'latest'  # Luôn là 'latest'
            ))
            print(f"{GREEN}Thêm mới thành công thông tin file cho app_id {app_id}{RESET}")
        
        connection.commit()

# Hàm lưu danh mục vào bảng app_category với thứ tự cha - con
def save_app_category(app_id, categories_list, connection):
    if not categories_list:
        print("Danh mục rỗng, không lưu được vào app_category")
        return

    # Danh mục cha là phần tử đầu tiên trong danh sách
    parent_category_id = categories_list[0]  # Gán danh mục cha là phần tử đầu tiên

    try:
        # Lưu danh mục cha trước
        with connection.cursor() as cursor:
            sql_query = """
            INSERT INTO app_category (app_id, category_id)
            SELECT %s, %s FROM DUAL WHERE NOT EXISTS (
                SELECT 1 FROM app_category WHERE app_id = %s AND category_id = %s
            ) LIMIT 1
            """
            cursor.execute(sql_query, (app_id, parent_category_id, app_id, parent_category_id))
            connection.commit()
            print(f"Lưu thành công danh mục cha với category_id {parent_category_id} cho app_id {app_id}")

        # Lưu các danh mục con (nếu có)
        sub_category_ids = categories_list[1:]  # Các danh mục con là các phần tử còn lại
        for sub_category_id in sub_category_ids:
            with connection.cursor() as cursor:
                sql_query = """
                INSERT INTO app_category (app_id, category_id)
                SELECT %s, %s FROM DUAL WHERE NOT EXISTS (
                    SELECT 1 FROM app_category WHERE app_id = %s AND category_id = %s
                ) LIMIT 1
                """
                cursor.execute(sql_query, (app_id, sub_category_id, app_id, sub_category_id))
                connection.commit()
                print(f"Lưu thành công danh mục con với category_id {sub_category_id} cho app_id {app_id}")

    except Exception as e:
        print(f"Lỗi khi lưu danh mục cho app_id {app_id}: {e}")

# Bản đồ chuyển đổi ngôn ngữ app_title_
unsupported_langs = ["ms", "fa", "bn"]
lang_mapping_title = {
    "en": "app_title_en",
    "id": "app_title_id",
    "ms": "app_title_ms",
    "de": "app_title_de",
    "es": "app_title_es",
    "fr": "app_title_fr",
    "it": "app_title_it",
    "nl": "app_title_nl",
    "pl": "app_title_pl",
    "pt": "app_title_pt",
    "vi": "app_title_vi",
    "tr": "app_title_tr",
    "ru": "app_title_ru",
    "ar": "app_title_ar",
    "fa": "app_title_fa",
    "hi": "app_title_hi",
    "bn": "app_title_bn",
    "th": "app_title_th",
    "ja": "app_title_ja",
    "zh": "app_title_zh",
    "zh-TW": "app_title_zh_tw",
    "ko": "app_title_ko"
    
}

lang_mapping_description = {
    "en": "app_description_en",
    "id": "app_description_id",
    "ms": "app_description_ms",
    "de": "app_description_de",
    "es": "app_description_es",
    "fr": "app_description_fr",
    "it": "app_description_it",
    "nl": "app_description_nl",
    "pl": "app_description_pl",
    "pt": "app_description_pt",
    "vi": "app_description_vi",
    "tr": "app_description_tr",
    "ru": "app_description_ru",
    "ar": "app_description_ar",
    "fa": "app_description_fa",
    "hi": "app_description_hi",
    "bn": "app_description_bn",
    "th": "app_description_th",
    "ja": "app_description_ja",
    "zh": "app_description_zh",
    "zh-TW": "app_description_zh_tw",
    "ko": "app_description_ko"
}

# Bản đồ chuyển đổi ngôn ngữ cho bảng app_summary_

lang_mapping_summary = {
    "en": "app_summary_en",
    "id": "app_summary_id",
    "ms": "app_summary_ms",
    "de": "app_summary_de",
    "es": "app_summary_es",
    "fr": "app_summary_fr",
    "it": "app_summary_it",
    "nl": "app_summary_nl",
    "pl": "app_summary_pl",
    "pt": "app_summary_pt",
    "vi": "app_summary_vi",
    "tr": "app_summary_tr",
    "ru": "app_summary_ru",
    "ar": "app_summary_ar",
    "fa": "app_summary_fa",
    "hi": "app_summary_hi",
    "bn": "app_summary_bn",
    "th": "app_summary_th",
    "ja": "app_summary_ja",
    "zh": "app_summary_zh",  # Điều chỉnh tên bảng cho zh-Hans
    "zh-TW": "app_summary_zh_tw",  # Điều chỉnh tên bảng cho zh-Hant
    "ko": "app_summary_ko"
}

# Hàm lọc URL ngôn ngữ từ thẻ hreflang
def extract_language_urls(soup):
    """
    Lọc các URL ngôn ngữ từ thẻ hreflang.
    """
    language_urls = {}
    languages = lang_mapping_title.keys()  # Sử dụng các ngôn ngữ trong lang_mapping
    
    # Sử dụng XPath để lấy danh sách các thẻ <link> với rel="alternate"
    alternate_links = soup.xpath("//link[@rel='alternate']")
    
    for link in alternate_links:
        hreflang = link.attrib.get("hreflang")
        href = link.attrib.get("href")
        
        # In log để kiểm tra giá trị của hreflang và href
        print(f"hreflang: {hreflang}, href: {href}")
        
        # Chỉ lấy các ngôn ngữ có trong danh sách ngôn ngữ hợp lệ
        if hreflang in languages:
            language_urls[hreflang] = href

    return language_urls


# Hàm kiểm tra app_id đã tồn tại trong bảng apps
def check_app_id_exists(app_id, connection):
    with connection.cursor() as cursor:
        sql = "SELECT id FROM apps WHERE google_play_id = %s"
        cursor.execute(sql, (app_id,))
        result = cursor.fetchone()
        if result:
            return result['id']  # Trả về id nếu tồn tại
        return None  # Trả về None nếu không tồn tại

# Hàm lưu tiêu đề vào bảng app_title_

def save_app_title_to_database(app_id, title, lang, connection):
    table_name = lang_mapping_title.get(lang)  # Lấy tên bảng tương ứng với ngôn ngữ
    if table_name:
        try:
            with connection.cursor() as cursor:
                cursor.execute("SELECT id FROM apps WHERE id = %s", (app_id,))
                result = cursor.fetchone()

                if result:
                    db_id = result['id']  # Lấy id từ bảng `apps`
                    # Sử dụng INSERT ... ON DUPLICATE KEY UPDATE thay vì kiểm tra
                    sql_query = f"""
                    INSERT INTO {table_name} (id, app_id, title, created_at, updated_at) 
                    VALUES (%s, %s, %s, NOW(), NOW())
                    ON DUPLICATE KEY UPDATE 
                    title = VALUES(title), updated_at = NOW()
                    """
                    cursor.execute(sql_query, (db_id, db_id, title))
                    connection.commit()
                    print(f"{CYAN}Lưu/cập nhật thành công tiêu đề '{title}' vào bảng `{table_name}` cho id {db_id}{RESET}")

                    # Xử lý các ngôn ngữ không được hỗ trợ
                    if lang == 'en':
                        for unsupported_lang in ['ms', 'fa', 'bn']:
                            unsupported_table = lang_mapping_title.get(unsupported_lang)
                            if unsupported_table:
                                # Cũng sử dụng INSERT ... ON DUPLICATE KEY UPDATE cho các ngôn ngữ không được hỗ trợ
                                cursor.execute(f"""
                                INSERT INTO {unsupported_table} (id, app_id, title, created_at, updated_at) 
                                VALUES (%s, %s, %s, NOW(), NOW())
                                ON DUPLICATE KEY UPDATE 
                                title = VALUES(title), updated_at = NOW()
                                """, (db_id, db_id, title))
                                connection.commit()
                                print(f"{CYAN}Sao chép/cập nhật tiêu đề từ 'en' sang bảng `{unsupported_table}` cho id {db_id}{RESET}")
                else:
                    print(f"Không tìm thấy id {app_id} trong bảng `apps`")
        except Exception as e:
            print(f"Lỗi khi lưu tiêu đề vào bảng `{table_name}` cho app_id {app_id}: {e}")
            connection.rollback()
    else:
        print(f"Không tìm thấy bảng cho ngôn ngữ {lang}")

# Hàm lưu mô tả ngắn vào bảng app_description_

def save_app_description_to_database(app_id, description, lang, connection):
    table_name = lang_mapping_description.get(lang)  # Lấy tên bảng tương ứng với ngôn ngữ
    if table_name:
        try:
            with connection.cursor() as cursor:
                cursor.execute("SELECT id FROM apps WHERE id = %s", (app_id,))
                result = cursor.fetchone()

                if result:
                    db_id = result['id']  # Lấy id từ bảng `apps`
                    # Sử dụng INSERT ... ON DUPLICATE KEY UPDATE thay vì kiểm tra
                    sql_query = f"""
                    INSERT INTO {table_name} (id, app_id, description, created_at, updated_at) 
                    VALUES (%s, %s, %s, NOW(), NOW())
                    ON DUPLICATE KEY UPDATE 
                    description = VALUES(description), updated_at = NOW()
                    """
                    cursor.execute(sql_query, (db_id, db_id, description))
                    connection.commit()
                    print(f"{CYAN}Lưu/cập nhật thành công mô tả ngắn vào bảng `{table_name}` cho id {db_id}{RESET}")

                    # Xử lý các ngôn ngữ không được hỗ trợ
                    if lang == 'en':
                        for unsupported_lang in ['ms', 'fa', 'bn']:
                            unsupported_table = lang_mapping_description.get(unsupported_lang)
                            if unsupported_table:
                                # Cũng sử dụng INSERT ... ON DUPLICATE KEY UPDATE cho các ngôn ngữ không được hỗ trợ
                                cursor.execute(f"""
                                INSERT INTO {unsupported_table} (id, app_id, description, created_at, updated_at) 
                                VALUES (%s, %s, %s, NOW(), NOW())
                                ON DUPLICATE KEY UPDATE 
                                description = VALUES(description), updated_at = NOW()
                                """, (db_id, db_id, description))
                                connection.commit()
                                print(f"{CYAN}Sao chép/cập nhật mô tả ngắn từ 'en' sang bảng `{unsupported_table}` cho id {db_id}{RESET}")
                else:
                    print(f"Không tìm thấy id {app_id} trong bảng `apps`")
        except Exception as e:
            print(f"Lỗi khi lưu mô tả ngắn vào bảng `{table_name}` cho app_id {app_id}: {e}")
    else:
        print(f"Không tìm thấy bảng cho ngôn ngữ {lang}")

# Hàm lưu nội dung chi tiết vào bảng app_summary_

def save_app_summary_to_database(app_id, content, lang, connection):
    table_name = lang_mapping_summary.get(lang)
    if not table_name:
        print(f"Không tìm thấy bảng cho ngôn ngữ {lang}")
        return

    try:
        with connection.cursor() as cursor:
            cursor.execute("SELECT id FROM apps WHERE id = %s", (app_id,))
            result = cursor.fetchone()

            if result:
                db_id = result['id']  # Lấy id từ bảng `apps`
                
                # Sử dụng INSERT ... ON DUPLICATE KEY UPDATE thay vì kiểm tra
                sql_query = f"""
                INSERT INTO {table_name} (id, app_id, summary, created_at, updated_at) 
                VALUES (%s, %s, %s, NOW(), NOW())
                ON DUPLICATE KEY UPDATE 
                summary = VALUES(summary), updated_at = NOW()
                """
                cursor.execute(sql_query, (db_id, db_id, content))
                connection.commit()
                print(f"{CYAN}Lưu thành công nội dung chi tiết vào bảng `{table_name}` cho id {db_id}{RESET}")

                # Xử lý các ngôn ngữ không được hỗ trợ
                if lang == 'en':
                    for unsupported_lang in ['ms', 'fa', 'bn']:
                        unsupported_table = lang_mapping_summary.get(unsupported_lang)
                        if unsupported_table:
                            # Cũng sử dụng INSERT ... ON DUPLICATE KEY UPDATE cho các ngôn ngữ không được hỗ trợ
                            cursor.execute(f"""
                            INSERT INTO {unsupported_table} (id, app_id, summary, created_at, updated_at) 
                            VALUES (%s, %s, %s, NOW(), NOW())
                            ON DUPLICATE KEY UPDATE 
                            summary = VALUES(summary), updated_at = NOW()
                            """, (db_id, db_id, content))
                            connection.commit()
                            print(f"{CYAN}Sao chép/cập nhật nội dung chi tiết từ 'en' sang bảng `{unsupported_table}` cho id {db_id}{RESET}")
            else:
                print(f"Không tìm thấy id {app_id} trong bảng `apps`")
    except Exception as e:
        print(f"Lỗi khi lưu nội dung chi tiết vào bảng `{table_name}` cho app_id {app_id}: {e}")
        connection.rollback()

# Hàm cào tiêu đề - title
from lxml import etree

def extract_full_title(soup):
    """
    Lấy tiêu đề đầy đủ từ thẻ <div class="app_name">
    """
    try:
        # Tìm thẻ <div class="app_name">
        title_container = soup.xpath("//div[@class='app_name']")[0]

        # Lấy nội dung bên trong <h1>
        h1_title = title_container.xpath(".//h1//text()")[0].strip() if title_container.xpath(".//h1//text()") else ""

        # Lấy toàn bộ nội dung văn bản từ <div>
        full_text = "".join(title_container.xpath(".//text()")).strip()

        # Ghép tiêu đề đầy đủ, giữ khoảng trắng sau h1
        full_title = full_text.replace(h1_title, "").strip()
        full_title = f"{h1_title} {full_title}".strip()

        # Xử lý khoảng trắng thừa nếu có
        full_title = " ".join(full_title.split())

        return full_title

    except Exception as e:
        print(f"Lỗi khi lấy tiêu đề: {e}")
        return "No title"


# Hàm cào nội dung chi tiết

def extract_full_content(soup):
    """
    Lấy nội dung chi tiết từ thẻ <div class="text-description ton">.
    """
    try:
        # Tìm thẻ chứa nội dung chi tiết
        content_div = soup.xpath("//div[@class='text-description ton']")
        if not content_div:
            return "Content Update" # Trả về thông báo nếu không tìm thấy thẻ

        # Chuyển nội dung thành chuỗi HTML
        full_content_html = etree.tostring(content_div[0], method="html", encoding="unicode").strip()
        return full_content_html
    except Exception as e:
        print(f"Lỗi khi lấy nội dung chi tiết: {e}")
        return "Content Update"

async def scrape_all_data(app_id, base_url, connection):
    """
    Hàm cào tất cả dữ liệu từ URL gốc, bao gồm tiêu đề, mô tả ngắn, gallery, icon, nội dung chi tiết.
    """
    try:
        headers = {
            "User-Agent": (
                "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"
                " AppleWebKit/537.36 (KHTML, like Gecko)"
                " Chrome/86.0.4240.111 Safari/537.36"
            )
        }

        # Xử lý ngôn ngữ mặc định (en) trước
        default_lang = "en"
        async with httpx.AsyncClient() as session:
            # Gửi yêu cầu đến URL chính
            response = await session.get(base_url, headers=headers, timeout=30)
            soup = etree.HTML(response.content)

            # Lưu URL các ngôn ngữ khác để xử lý sau
            language_urls = extract_language_urls(soup)
            print(f"Đã tìm thấy {len(language_urls)} ngôn ngữ khác: {list(language_urls.keys())}")

            # Xử lý dữ liệu tiếng Anh
            default_title = extract_full_title(soup)
            print(f"Tiêu đề mặc định (en): {default_title}")
            save_app_title_to_database(app_id, default_title, default_lang, connection)

            # Lấy mô tả ngắn mặc định
            description_short_node = soup.xpath(
                "//h2[contains(@class, 'mt-14') and contains(@class, 'mb-14') and contains(@class, 'short-description')]/text()"
            )
            default_short_description = (
                description_short_node[0].strip()
                if description_short_node
                else "Description Update"
            )
            save_app_description_to_database(app_id, default_short_description, default_lang, connection)

            # Lấy nội dung chi tiết mặc định
            full_content_html = extract_full_content(soup)
            default_cleaned_content = clean_html_content(full_content_html)
            save_app_summary_to_database(app_id, default_cleaned_content, default_lang, connection)

            # Lấy gallery
            gallery_urls = extract_gallery_urls(soup)
            gallery_html = generate_gallery_html(gallery_urls, default_title)
            save_gallery_html_to_screenshots_table(app_id, gallery_html, connection)

            # Giải phóng bộ nhớ
            soup = None
            response = None
            gallery_urls = None
            gallery_html = None
            full_content_html = None
            default_cleaned_content = None
            gc.collect()

        # Xử lý riêng từng ngôn ngữ với phiên làm việc mới để giải phóng bộ nhớ sau mỗi ngôn ngữ
        for lang, lang_url in language_urls.items():
            if lang != default_lang and lang in lang_mapping_title:
                try:
                    print(f"Cào dữ liệu cho ngôn ngữ: {lang} từ URL: {lang_url}")
                    async with httpx.AsyncClient() as lang_session:
                        lang_response = await lang_session.get(lang_url, headers=headers, timeout=30)
                        lang_soup = etree.HTML(lang_response.content)
                        
                        # Lấy tiêu đề
                        lang_title = extract_full_title(lang_soup)
                        save_app_title_to_database(app_id, lang_title, lang, connection)
                        
                        # Lấy mô tả ngắn
                        lang_desc_node = lang_soup.xpath(
                            "//h2[contains(@class, 'mt-14') and contains(@class, 'mb-14') and contains(@class, 'short-description')]/text()"
                        )
                        lang_short_description = (
                            lang_desc_node[0].strip() if lang_desc_node else default_short_description
                        )
                        save_app_description_to_database(app_id, lang_short_description, lang, connection)
                        
                        # Lấy nội dung chi tiết
                        lang_content_html = extract_full_content(lang_soup)
                        lang_cleaned_content = clean_html_content(lang_content_html)
                        save_app_summary_to_database(app_id, lang_cleaned_content, lang, connection)
                        
                    # Giải phóng bộ nhớ sau mỗi ngôn ngữ
                    lang_soup = None
                    lang_response = None
                    lang_content_html = None
                    lang_cleaned_content = None
                    gc.collect()
                    
                    print(f"Lưu thành công dữ liệu ngôn ngữ: {lang}")
                except Exception as e:
                    print(f"Lỗi khi cào dữ liệu ngôn ngữ {lang}: {e}")
                    # Nếu không thể cào được, sao chép từ tiếng Anh
                    print(f"Sao chép dữ liệu từ tiếng Anh sang ngôn ngữ {lang}")
                    save_app_title_to_database(app_id, default_title, lang, connection)
                    save_app_description_to_database(app_id, default_short_description, lang, connection)
                    save_app_summary_to_database(app_id, default_cleaned_content, lang, connection)
                    
                # Ngưng một chút để giải phóng bộ nhớ giữa các ngôn ngữ
                await asyncio.sleep(0.1)

        # Lấy các ngôn ngữ không được hỗ trợ và sao chép dữ liệu từ "en"
        for unsupported_lang in unsupported_langs:
            if unsupported_lang not in language_urls:
                print(f"Sao chép dữ liệu sang ngôn ngữ không được hỗ trợ: {unsupported_lang}")
                save_app_title_to_database(app_id, default_title, unsupported_lang, connection)
                save_app_description_to_database(app_id, default_short_description, unsupported_lang, connection)
                save_app_summary_to_database(app_id, default_cleaned_content, unsupported_lang, connection)

    except Exception as e:
        print(f"Lỗi khi cào dữ liệu chính: {e}")
    finally:
        # Giải phóng bộ nhớ cuối cùng
        gc.collect()
        print("Đã giải phóng tài nguyên sau khi xử lý.")



# Hàm tạo HTML gallery từ danh sách URL (với ảnh thu nhỏ và ảnh lớn)
def generate_gallery_html(gallery_urls, title):
    gallery_html = '''
    <div class="mb-3">
        <div class="swiper gallery_image_top swiper-initialized swiper-horizontal">
            <h3 id="screenshots">Screenshots</h3>
            <div class="swiper-wrapper" aria-live="polite">
    '''

    for idx, (thumbnail_url, full_image_url) in enumerate(gallery_urls[:15]):  # Lấy tối đa 15 ảnh đầu tiên
        # Đảm bảo href sử dụng URL ảnh lớn (full_image_url)
        gallery_html += f'''
            <div class="swiper-slide" style="width: 160px; margin-right: 5px;" role="group" aria-label="{idx + 1} / {min(len(gallery_urls), 15)}">
                <a href="{full_image_url}" itemprop="screenshot" data-fancybox="img_top" rel="noopener nofollow noreferrer">
                    <img src="/wp-content/themes/apkhay/img/lazy.gif" data-src="{thumbnail_url}" data-srcset="{thumbnail_url}" title="{title}" alt="{title}" class="app-logo lazy">
                </a>
                <br>
            </div>
        '''

    gallery_html += '''
            </div>
        </div>
    </div>
    '''
    return gallery_html

# Hàm lưu data gallery vào bảng app_screenshots với id và app_id đồng nhất từ bảng apps
def save_gallery_html_to_screenshots_table(apps_id, gallery_html, connection):
    try:
        with connection.cursor() as cursor:
            # Kiểm tra `id` có tồn tại trong bảng `apps`
            cursor.execute("SELECT id FROM apps WHERE id = %s", (apps_id,))
            result = cursor.fetchone()

            if result:
                db_id = result['id']  # Lấy id từ bảng `apps`

                # Kiểm tra nếu app_id đã tồn tại trong bảng app_screenshots
                cursor.execute("SELECT app_id FROM app_screenshots WHERE app_id = %s", (db_id,))
                existing_entry = cursor.fetchone()

                if not existing_entry:
                    # Lưu dữ liệu vào bảng `app_screenshots` với `id` và `app_id` từ bảng `apps`
                    sql_query = """
                    INSERT INTO app_screenshots (id, app_id, link, created_at, updated_at)
                    VALUES (%s, %s, %s, NOW(), NOW())
                    """
                    cursor.execute(sql_query, (db_id, db_id, gallery_html if gallery_html else ''))
                    connection.commit()
                    print(f"{MAGENTA}Lưu thành công dữ liệu gallery vào bảng `app_screenshots` cho id {db_id}{RESET}")
                else:
                    # Cập nhật dữ liệu gallery nếu đã tồn tại
                    sql_query = """
                    UPDATE app_screenshots 
                    SET link = %s, updated_at = NOW()
                    WHERE app_id = %s
                    """
                    cursor.execute(sql_query, (gallery_html if gallery_html else '', db_id))
                    connection.commit()
                    print(f"{YELLOW}Cập nhật dữ liệu gallery cho id {db_id} trong bảng `app_screenshots`{RESET}")

            else:
                print(f"{YELLOW}id {apps_id} không tồn tại trong bảng `apps`{RESET}")

    except Exception as e:
        print(f"Lỗi khi lưu dữ liệu gallery vào bảng `app_screenshots`: {e}")

# Hàm format lại nội dung bài viết
def format_post_content(post_title, post_slug, scraped_content, image_urls, gallery_html, app_ids, lang_code):

    post_content = f'''
     {scraped_content}
    
    '''
   
    return post_content

# def schedule_publication(lenlich):
#     # Tạo số giây ngẫu nhiên trong khoảng 5-10 giây
#     random_seconds = random.randint(5, 10)
#     lenlich += timedelta(seconds=random_seconds)
#     return lenlich


# Hàm lên lịch public bài viết
def schedule_publication(lenlich):
    # Tạo số phút ngẫu nhiên trong khoảng 5-10 phút
    random_minutes = random.randint(1, 3)
    lenlich += timedelta(minutes=random_minutes)
    return lenlich

# Hàm lưu vào bảng tương ứng với từng ngôn ngữ
def save_to_language_table(app_id, lang_code, content, connection):
    # Lấy tên bảng từ lang_mapping_summary
    table_name = lang_mapping_summary.get(lang_code)

    if not table_name:
        print(f"Không tìm thấy bảng cho ngôn ngữ {lang_code}")
        return

    # Bao quanh tên bảng bằng dấu ` để tránh lỗi cú pháp
    table_name = f"`{table_name}`"
    current_time = datetime.datetime.now()

    # Kiểm tra xem có bản ghi cho app_id này trong bảng ngôn ngữ chưa
    check_query = f"SELECT app_id FROM {table_name} WHERE app_id = %s"
    sql_query = f"""
        INSERT INTO {table_name} (app_id, summary, created_at, updated_at)
        VALUES (%s, %s, %s, %s)
    """

    # Cập nhật lại logic INSERT cho đúng với tên cột
    with connection.cursor() as cursor:
        cursor.execute(check_query, (app_id,))
        result = cursor.fetchone()

        if result:
            print(f"Dữ liệu cho app_id {app_id} trong bảng `{table_name}` đã tồn tại.")
        else:
            cursor.execute(sql_query, (app_id, content, current_time, current_time))
            connection.commit()
            print(f"Lưu thành công vào bảng {table_name} cho app_id {app_id}")


 # Hàm lấy id lớn nhất từ bảng apps
def get_max_app_id(connection):
    with connection.cursor() as cursor:
        cursor.execute("SELECT MAX(id) AS max_id FROM apps")
        result = cursor.fetchone()
        return result['max_id'] if result['max_id'] is not None else 0  # Nếu không có kết quả trả về 0

# Khai báo biến đếm toàn cục
counter = 0
update_count = 0  # Đếm số lượng app đã cập nhật
insert_count = 0  # Đếm số lượng app đã thêm mới

# Hàm lưu ứng dụng vào bảng apps với id tiếp theo
def save_app_to_database(app_data, connection):
    # Khai báo biến đếm là toàn cục để có thể cập nhật
    global update_count, insert_count

    # Kiểm tra nếu app_id đã tồn tại trước khi lưu
    existing_id = check_app_id_exists(app_data['google_play_id'], connection)
    if existing_id:
        print(f"{YELLOW}App ID '{app_data['google_play_id']}' đã tồn tại trong database. Đang cập nhật dữ liệu...{RESET}")
        # Cập nhật dữ liệu cho app_id đã tồn tại
        with connection.cursor() as cursor:
            sql_query = """
            UPDATE apps 
            SET name = %s, slug = %s, google_play_url = %s, 
                price_text = %s, price = %s, developer_name = %s, app_version = %s, 
                updated_date = %s, icon = %s, thumbnail = %s, score = %s, number_voters = %s, 
                android_version = %s, min_android_version = %s, installs = %s, installs_text = %s
            WHERE id = %s
            """
            try:
                cursor.execute(sql_query, (
                    app_data['name'], app_data['slug'], app_data['google_play_url'],
                    app_data['price_text'], app_data['price'], app_data['developer_name'], app_data['app_version'],
                    app_data['updated_date'], app_data['icon'], app_data['thumbnail'], app_data['score'], 
                    app_data['number_voters'], app_data['android_version'], app_data['min_android_version'],
                    app_data['installs'], app_data['installs_text'], existing_id
                ))
                connection.commit()
                update_count += 1  # Tăng biến đếm số lượng cập nhật
                print(f"{GREEN}Cập nhật thành công dữ liệu cho App ID '{app_data['google_play_id']}'{RESET}")
            except Exception as e:
                print(f"Lỗi khi cập nhật dữ liệu cho App ID '{app_data['google_play_id']}': {e}")
                connection.rollback()
        return existing_id  # Trả về id hiện có

    # Nếu app_id chưa tồn tại, thêm mới vào database
    max_id = get_max_app_id(connection) + 1  # Lấy id tiếp theo

    # Thực hiện lưu vào database
    with connection.cursor() as cursor:
        sql_query = """
        INSERT INTO apps (
            id, name, slug, google_play_id, google_play_url, 
            price_text, price, developer_name, app_version, 
            updated_date, icon, thumbnail, score, number_voters, 
            android_version, min_android_version, installs, installs_text, 
            published_at, status
        ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
        """
        try:
            cursor.execute(sql_query, (
                max_id,
                app_data['name'], app_data['slug'], app_data['google_play_id'], app_data['google_play_url'],
                app_data['price_text'], app_data['price'], app_data['developer_name'], app_data['app_version'],
                app_data['updated_date'], app_data['icon'], app_data['thumbnail'], app_data['score'], 
                app_data['number_voters'], app_data['android_version'], app_data['min_android_version'],
                app_data['installs'], app_data['installs_text'], app_data['published_at'],
                app_data['status']
            ))
            connection.commit()
            insert_count += 1  # Tăng biến đếm số lượng thêm mới
            print(f"{GREEN}Thêm mới thành công App ID '{app_data['google_play_id']}'{RESET}")
        except pymysql.err.IntegrityError as e:
            print(f"Lỗi trùng lặp khi lưu App ID '{app_data['google_play_id']}': {e}")
            return None  # Bỏ qua nếu gặp lỗi trùng lặp

    return max_id  # Trả về id của ứng dụng vừa được lưu

# Hàm kiểm tra lỗi 404 và phân biệt lỗi 410 giả
async def check_url_error(url):
    try:
        async with httpx.AsyncClient(timeout=30) as client:
            response = await client.get(url)

            # Kiểm tra mã trạng thái 410
            if response.status_code == 410:
                print(f"URL '{url}' có lỗi 410. Bỏ qua URL này.")
                return True

            # Kiểm tra mã trạng thái 404 và nội dung trang
            if response.status_code == 404:
                page_content = response.text
                if "Oopps! The page can't be found." in page_content:
                    print(f"URL '{url}' có lỗi 410 giả. Bỏ qua URL này.")
                    return True
                if "404 - Page Not Found" in page_content or "Sorry, the page you are looking for does not exist." in page_content:
                    print(f"URL '{url}' có lỗi 404. Bỏ qua URL này.")
                    return True

            return False  # Không phải lỗi 404/410

    except httpx.RequestError as e:
        print(f"Lỗi kết nối khi kiểm tra URL '{url}': {e}")
        return True  # Bỏ qua URL này nếu gặp lỗi kết nối

    
# Hàm lấy dữ liệu từ thẻ ld+json với @type="MobileApplication"
def extract_ld_json(soup):
    """
    Lấy rating_value và rating_count từ thẻ ld+json với @type="MobileApplication".
    """
    try:
        # Sử dụng XPath để tìm tất cả các thẻ <script> với @type="application/ld+json"
        ld_json_tags = soup.xpath("//script[@type='application/ld+json']/text()")
        
        # Biến lưu giá trị mặc định nếu không tìm thấy
        rating_value = "0"
        rating_count = "0"

        for ld_json_text in ld_json_tags:
            try:
                # Parse JSON từ thẻ ld+json
                ld_json_data = json.loads(ld_json_text)
                
                # Kiểm tra nếu @type là MobileApplication
                if ld_json_data.get("@type") == "MobileApplication":
                    # Lấy rating_value và rating_count từ aggregateRating
                    aggregate_rating = ld_json_data.get("aggregateRating", {})
                    rating_value = aggregate_rating.get("ratingValue", "5")
                    rating_count = aggregate_rating.get("reviewCount", "10")
                    
                    # In log kiểm tra giá trị JSON
                    # print(f"JSON trích xuất từ ld+json: {ld_json_data}") # hiển thị dữ liệu json
                    break  # Dừng vòng lặp khi đã tìm thấy thẻ cần thiết
            except json.JSONDecodeError as e:
                print(f"Lỗi khi giải mã ld+json: {e}")
        
        return rating_value, rating_count
    except Exception as e:
        print(f"Lỗi khi trích xuất thẻ ld+json: {e}")
        return rating_value, rating_count

# Hàm lấy phiên bản của app
def extract_version(soup):
    try:
        version_node = soup.xpath("//div[@class='item']//div[@class='name' and text()='Version']/following-sibling::div[@class='value']")
        if version_node:
            # Lấy nội dung văn bản trong thẻ <a> và <span>
            version_text = version_node[0].xpath(".//a/text()")[0].strip() if version_node[0].xpath(".//a/text()") else ""
            blur_text = version_node[0].xpath(".//span[@class='blur']/text()")[0].strip() if version_node[0].xpath(".//span[@class='blur']/text()") else ""
            # Ghép thông tin lại
            version = f"{version_text} {blur_text}".strip()
            return version
        else:
            return "Không có phiên bản"
    except Exception as e:
        print(f"Lỗi khi lấy phiên bản: {e}")
        return "Không có phiên bản"


# Hàm cào đa ngôn ngữ
async def scrape_apkpure(url, app_id):
    global connection, Lenlich  # Biến toàn cục

    try:
        # Lấy app_id từ URL
        app_id_from_url = url.rstrip("/").split("/")[-1]
        
        # Kiểm tra và tạo lại kết nối nếu cần
        if connection is None or not connection.open:
            connection = create_new_connection()

        # Tạo async client cho HTTP trong khối try để đảm bảo đóng đúng cách
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.111 Safari/537.36",
            "Connection": "close"
        }

        # Dùng async with để đảm bảo giải phóng tài nguyên sau khi sử dụng xong
        async with httpx.AsyncClient() as scraper:
            # Gửi yêu cầu GET
            response = await scraper.get(url, headers=headers, timeout=30)
            parser = etree.HTMLParser()
            soup = etree.fromstring(response.content, parser)

            # Kiểm tra thẻ <title>
            page_title = soup.xpath("//h1/text()")[0].strip() if soup.xpath("//h1/text()") else ""
            if "404" in page_title or "Access denied" in page_title or "Whoops, 404" in page_title:
                print(f"URL '{url}' không hợp lệ hoặc gặp lỗi 404. Bỏ qua.")
                return

            # Trích xuất tiêu đề từ thẻ <h1>
            title_elements = soup.xpath("//h1//text()")  # Trích xuất tất cả văn bản trong thẻ <h1>

            if title_elements:
                post_title = "".join(title_elements).strip()  # Kết hợp các phần văn bản từ thẻ <h1>
            else:
                post_title = "Không có tiêu đề"

            if post_title == "Không có tiêu đề":
                print(f"Không tìm thấy tiêu đề tại URL '{url}'.")
                return
            else:
                print(f"Tiêu đề tìm thấy: {post_title}")

            # Tạo slug từ tiêu đề
            post_slug = generate_slug(post_title)
            
            # Lấy rating_value và rating_count từ ld+json hoặc từ các thẻ HTML tương ứng
            rating_value, rating_count = extract_ld_json(soup)

            # Lấy số lượt cài đặt từ thẻ "Installs"
            installs_node = soup.xpath("//div[@class='item']//div[@class='name' and text()='Installs']/following-sibling::div[@class='value']/text()")
            installs_text = installs_node[0].strip() if installs_node else "10"

            # Chuyển đổi số lượt cài đặt thành số nguyên
            installs_str = re.sub(r'\D', '', installs_text)  # Loại bỏ ký tự không phải số
            installs = int(installs_str) if installs_str.isdigit() else 0

            # Debug log để kiểm tra
            print(f"Installs Text: {installs_text}, Installs (Numeric): {installs}")

            # Developer
            developer_node = soup.xpath("//div[@class='author']//a/text()")
            developer_name = developer_node[0].strip() if developer_node else "N/A"

            # Icon có =s75-rw
            icon_node = soup.xpath("//div[@class='avatar']//img/@data-src")
            image_url = icon_node[0] if icon_node else None

            # Đoạn mã xử lý breadcrumb trong trang
            # Xử lý breadcrumb
            breadcrumb_nodes = soup.xpath("//nav[@class='breadcrumb']//p//a/@href")
            print(f"{YELLOW}Breadcrumb nodes: {breadcrumb_nodes}{RESET}")

            if breadcrumb_nodes:
                categories_list = map_category_from_breadcrumbs(breadcrumb_nodes)
                print(f"{YELLOW}Danh mục lấy được: {categories_list}{RESET}")
            else:
                print(f"{RED}Không tìm thấy breadcrumb nodes. Kiểm tra lại XPath hoặc HTML cấu trúc.{RESET}")
                categories_list = []

            # Lấy phiên bản của app
            version = extract_version(soup)
            print(f"Phiên bản: {version}")

            # Lấy kích thước file
            size_node = soup.xpath("//div[@class='button-group mb-14']//span[@class='fsize']/span/text()")
            file_size = size_node[0].strip() if size_node else "No File Size"

            # Lấy thông tin phiên bản Android từ thẻ 'description'
            android_version_info = None
            additional_items = soup.xpath("//div[@class='info']")
            for item in additional_items:
                description = item.xpath(".//div[@class='description']")
                if description and "Android" in description[0].text:
                    android_version_info = description[0].text.strip()
                    break  # Dừng tìm kiếm sau khi tìm thấy thông tin yêu cầu Android

            # Sử dụng biểu thức chính quy để lấy phiên bản Android
            if android_version_info:
                match = re.search(r'Android\s(\d+(\.\d+)?)', android_version_info)
                if match:
                    android_version = match.group(1)  # Lấy phần số từ chuỗi
                else:
                    android_version = "Không có thông tin PB"
            else:
                android_version = "5.1+"  # Mặc định yêu cầu phiên bản Android

            # Tạo dữ liệu ứng dụng
            app_data = {
                'name': post_title,
                'slug': post_slug,
                'google_play_id': app_id_from_url,
                'google_play_url': f"https://play.google.com/store/apps/details?id={app_id_from_url}",
                'price_text': 'Free',
                'price': '0',
                'developer_name': developer_name,
                'app_version': version,
                'updated_date': Lenlich.strftime('%Y-%m-%d %H:%M:%S'), 
                'icon': image_url,
                'thumbnail': image_url,
                'score': rating_value,
                'number_voters': rating_count,
                'android_version': android_version,
                'min_android_version': android_version,
                'installs': installs,
                'installs_text': installs_text,
                'published_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'status': 'Published'
            }

            # Giải phóng một số biến lớn để giải phóng bộ nhớ
            soup = None
            response = None
            gc.collect()

            # Biến Lên Lịch ( status Pending table apps )
            Lenlich = schedule_publication(Lenlich)
            
            # Lưu hoặc cập nhật app vào bảng apps
            app_id_db = save_app_to_database(app_data, connection)
            
            if app_id_db:
                # Lưu hoặc cập nhật thông tin file
                file_data = {
                    'google_play_id': app_id_from_url,
                    'file_size': file_size,
                    'version': version
                }
                save_app_file_to_database(file_data, app_id_db, connection)
                
                # Lưu hoặc cập nhật danh mục
                save_app_category(app_id_db, categories_list, connection)
                
                # Cào và lưu dữ liệu ngôn ngữ
                await scrape_all_data(app_id_db, url, connection)
                
    except Exception as e:
        print(f"Lỗi khi cào dữ liệu từ URL '{url}': {e}")
    finally:
        # Đảm bảo giải phóng bộ nhớ
        gc.collect()
        print("Đã giải phóng tài nguyên sau khi xử lý.")



# Hàm thu gom rác thủ công
def collect_garbage():
    # Khai báo biến toàn cục cần được thu gom
    global data, soup, response, gallery_urls, gallery_html, lang_soup, lang_response
    
    # Xóa các biến lớn nếu tồn tại
    for var in ['data', 'soup', 'response', 'gallery_urls', 'gallery_html', 'lang_soup', 'lang_response']:
        if var in globals():
            globals()[var] = None
            print(f"Đã xóa biến {var}.")
    
    # Giải phóng bộ nhớ chưa sử dụng
    import sys
    memory_before = sys.getsizeof(0)  # Lấy kích thước bộ nhớ trước khi thu gom
    
    # Gọi trình thu gom rác nhiều lần để đảm bảo giải phóng triệt để
    gc.collect(2)  # Thu gom triệt để nhất (generation 2)
    
    # In thông tin giải phóng bộ nhớ
    print("Đã thu gom rác để giảm bộ nhớ.")
    
    # Gợi ý Python giải phóng bộ nhớ trả lại cho hệ điều hành (chỉ có tác dụng trên một số nền tảng)
    try:
        import ctypes
        ctypes.pythonapi.PyGC_Collect()
        ctypes.pythonapi.malloc_trim(0)
    except (ImportError, AttributeError):
        pass

# Đếm số lượng app đã cào để giải phóng kết nối sau mỗi 10 app
counter = 0

def get_max_id_from_database():
    try:
        with connection.cursor() as cursor:
            # Lấy giá trị max_id từ bảng apps
            cursor.execute("SELECT MAX(id) AS max_id FROM apps")
            result = cursor.fetchone()
            return result['max_id'] if result['max_id'] else 0  # Trả về 0 nếu không có dữ liệu
    except Exception as e:
        print(f"Lỗi khi lấy max_id từ database: {e}")
        return 0
    
# Thêm hàm ghi log thống kê
def write_statistics_to_log(stats_data):
    try:
        log_file = "crawler_statistics.log"
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        with open(log_file, "a", encoding="utf-8") as f:
            f.write(f"===== THỐNG KÊ [{timestamp}] =====\n")
            for key, value in stats_data.items():
                f.write(f"{key}: {value}\n")
            f.write("============================\n\n")
            
        print(f"{GREEN}Đã ghi thống kê vào file {log_file}{RESET}")
    except Exception as e:
        print(f"{RED}Lỗi khi ghi log thống kê: {e}{RESET}")

async def scrape_from_directory(directory_path):
    global counter, connection, update_count, insert_count  # Khai báo biến toàn cục

    # Khởi tạo thời gian bắt đầu của toàn bộ quá trình cào
    start_time = time.time()
    processed_count = 0  # Đếm số URL đã xử lý
    error_count = 0  # Đếm số lỗi

    # Tạo biến để quản lý dải ID
    file_id_ranges = {}

    # Sắp xếp và lặp qua tất cả các file trong thư mục theo thứ tự tên
    for filename in sorted(os.listdir(directory_path)):
        if filename.endswith(".txt"):
            file_path = os.path.join(directory_path, filename)

            # Lấy dải ID từ bảng id_manager
            start_id, end_id = allocate_id_range(30000)  # Dải ID cho mỗi file

            # Gán dải ID cho file TXT hiện tại
            file_id_ranges[filename] = IDAllocator(start_id, end_id)

            # Đọc nội dung file
            with open(file_path, 'r', encoding='utf-8') as file:
                urls = file.readlines()

            print(f"{GREEN}Đang xử lý file {filename} với {len(urls)} URL...{RESET}")

            # Lặp qua từng URL trong file
            while urls:
                url = urls.pop(0).strip()  # Lấy và loại bỏ URL đầu tiên
                if url:
                    try:
                        # Kiểm tra và tạo lại kết nối nếu cần
                        if connection is None or not connection.open:
                            print("Kết nối đã bị đóng hoặc không tồn tại. Đang tạo lại kết nối...")
                            connection = create_new_connection()  # Tạo lại kết nối mới

                        # Lấy ID từ dải của file hiện tại
                        allocator = file_id_ranges[filename]
                        try:
                            app_id = allocator.get_next_id()
                        except Exception as e:
                            print(f"{RED}Dải ID cho file {filename} đã hết. Không thể gán thêm ID.{RESET}")
                            break

                        # Gọi hàm để cào dữ liệu từ URL
                        print(f"{CYAN}Đang cào URL {url} (#{processed_count + 1})...{RESET}")
                        await scrape_apkpure(url, app_id)  # Truyền app_id vào hàm cào
                        processed_count += 1
                        counter += 1

                        # Hiển thị thống kê sau mỗi URL
                        print(f"{MAGENTA}Thống kê hiện tại: Đã xử lý {processed_count} URL, Thêm mới: {insert_count}, Cập nhật: {update_count}{RESET}")

                        # Ghi thống kê vào file log sau mỗi 10 URL
                        if processed_count % 10 == 0:
                            stats_data = {
                                "Số URL đã xử lý": processed_count,
                                "Số app đã thêm mới": insert_count,
                                "Số app đã cập nhật": update_count,
                                "Số lỗi": error_count,
                                "Tỷ lệ thành công": f"{((insert_count + update_count) / processed_count * 100):.2f}%" if processed_count > 0 else "0%"
                            }
                            write_statistics_to_log(stats_data)

                        # Thu gom rác sau mỗi lần cào
                        collect_garbage()

                        # Giải phóng bộ nhớ một cách quyết liệt sau mỗi 5 URL
                        if processed_count % 5 == 0:
                            print(f"{YELLOW}Đang thực hiện giải phóng bộ nhớ toàn diện sau {processed_count} URL...{RESET}")
                            # Gọi collect_garbage nhiều lần để đảm bảo giải phóng bộ nhớ
                            for _ in range(3):
                                collect_garbage()
                                await asyncio.sleep(0.5)  # Cho GC có thời gian làm việc

                        # Sau mỗi 10 app thì giải phóng và tạo lại kết nối
                        if counter % 10 == 0:
                            if connection:
                                connection.close()
                                print(f"{YELLOW}Đã đóng kết nối database để giải phóng bộ nhớ.{RESET}")
                            connection = None  # Đặt là None trước khi tạo mới
                            create_new_connection()  # Mở lại kết nối mới
                            print(f"{YELLOW}Đã tạo kết nối mới để tiếp tục cào.{RESET}")

                        # Ghi lại file sau khi xóa URL đã xử lý
                        with open(file_path, 'w', encoding='utf-8') as file:
                            file.writelines([f"{u.strip()}\n" for u in urls])

                        # Đếm ngược 1 giây sau khi cào xong 1 URL
                        for i in range(1, 0, -1):
                            print(f"{GREEN}Đợi {i} giây...{RESET}", end="\r")
                            await asyncio.sleep(1)

                    except Exception as e:
                        print(f"{RED}Lỗi khi xử lý URL {url}: {e}{RESET}")
                        error_count += 1  # Tăng số lỗi
                        # Vẫn ghi lại file để loại bỏ URL gây lỗi
                        with open(file_path, 'w', encoding='utf-8') as file:
                            file.writelines([f"{u.strip()}\n" for u in urls])
                    
                    print(f"{GREEN}Tiếp tục cào dữ liệu...{RESET}")

    # Khởi tạo thời gian kết thúc sau khi toàn bộ quá trình cào hoàn tất
    end_time = time.time()
    total_time = end_time - start_time
    minutes, seconds = divmod(int(total_time), 60)
    hours, minutes = divmod(minutes, 60)
    
    # Tạo thống kê cuối cùng
    final_stats = {
        "Đã xử lý tổng cộng": f"{processed_count} URL",
        "Số app đã thêm mới": insert_count,
        "Số app đã cập nhật": update_count,
        "Tổng số app xử lý": insert_count + update_count,
        "Số lỗi gặp phải": error_count,
        "Tỷ lệ thành công": f"{((insert_count + update_count) / processed_count * 100):.2f}%" if processed_count > 0 else "0%",
        "Tổng thời gian chạy": f"{hours:02d}:{minutes:02d}:{seconds:02d}"
    }
    
    # Ghi thống kê cuối cùng vào file log
    write_statistics_to_log(final_stats)
    
    # Hiển thị thống kê cuối cùng
    print(f"{GREEN}===== THỐNG KÊ CUỐI CÙNG ====={RESET}")
    for key, value in final_stats.items():
        print(f"{GREEN}{key}: {value}{RESET}")
    print(f"{GREEN}============================{RESET}")

# Hàm cập nhật `current_id` sau mỗi lần lấy ID
def update_current_id(last_app_id):
    try:
        with connection.cursor() as cursor:
            # Cập nhật current_id trong bảng id_manager sau mỗi lần lấy ID
            cursor.execute("UPDATE id_manager SET current_id = %s WHERE id_name = 'apps'", (last_app_id + 1,))
            connection.commit()
            print(f"{GREEN}Đã cập nhật current_id thành {last_app_id + 1}{RESET}")
    except Exception as e:
        print(f"Lỗi khi cập nhật current_id: {e}")
        connection.rollback()


# Đường dẫn đến thư mục chứa các file txt
# directory_path = 'apkcombo-link/apktest'
directory_path = 'apkcombo-link/task1'

# Gọi hàm để cào dữ liệu từ thư mục
async def main():
    await scrape_from_directory(directory_path)

# Chạy hàm bất đồng bộ chính
asyncio.run(main())

# Sau khi hoàn thành cào, đóng kết nối database
if 'connection' in globals() and connection:
    connection.close()
    print(f"{GREEN}Đã đóng kết nối database sau khi hoàn thành.{RESET}")

gc.collect()
